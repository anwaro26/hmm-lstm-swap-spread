{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diebold Mariano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched HMM-LSTM: {(60, 1): 'HMM_LSTM_split_60_H1.csv', (60, 12): 'HMM_LSTM_split_60_H12.csv', (60, 4): 'HMM_LSTM_split_60_H4.csv', (70, 1): 'HMM_LSTM_split_70_H1.csv', (70, 12): 'HMM_LSTM_split_70_H12.csv', (70, 4): 'HMM_LSTM_split_70_H4.csv', (80, 1): 'HMM_LSTM_split_80_H1.csv', (80, 12): 'HMM_LSTM_split_80_H12.csv', (80, 4): 'HMM_LSTM_split_80_H4.csv', (90, 1): 'HMM_LSTM_split_90_H1.csv', (90, 12): 'HMM_LSTM_split_90_H12.csv', (90, 4): 'HMM_LSTM_split_90_H4.csv'}\n",
      "Matched LSTM (NEW): {(60, 1): 'LSTM_split_60_H1.csv', (60, 12): 'LSTM_split_60_H12.csv', (60, 4): 'LSTM_split_60_H4.csv', (70, 1): 'LSTM_split_70_H1.csv', (70, 12): 'LSTM_split_70_H12.csv', (70, 4): 'LSTM_split_70_H4.csv', (80, 1): 'LSTM_split_80_H1.csv', (80, 12): 'LSTM_split_80_H12.csv', (80, 4): 'LSTM_split_80_H4.csv', (90, 1): 'LSTM_split_90_H1.csv', (90, 12): 'LSTM_split_90_H12.csv', (90, 4): 'LSTM_split_90_H4.csv'}\n",
      "Saved per-split results → /Users/anwarouni/Downloads/Thesis/DM tests (HMM v LSTM NEW)/DM_HMM_LSTM_vs_LSTM_NEW_by_split_MSE_one_sided_HLN.csv\n",
      "Saved pooled results → /Users/anwarouni/Downloads/Thesis/DM tests (HMM v LSTM NEW)/DM_HMM_LSTM_vs_LSTM_NEW_by_horizon_MSE_one_sided_HLN.csv\n",
      "\n",
      "============= ONE-SIDED DM (HMM-LSTM better) — MSE (HLN ON) =============\n",
      "\n",
      "H = 1\n",
      "Split  N    MSE_LSTM  MSE_HMM  dbar     DM      p     sig  q\n",
      "  60   132     0.0009    0.0008   0.0000  0.6561  0.2559       0\n",
      "  70   132     0.0007    0.0007   0.0000  1.1556  0.1239       0\n",
      "  80   132     0.0016    0.0017  -0.0001  -0.9954  0.8402       0\n",
      "  90   133     0.0014    0.0013   0.0000  1.4308  0.0762    *  0\n",
      "\n",
      "H = 4\n",
      "Split  N    MSE_LSTM  MSE_HMM  dbar     DM      p     sig  q\n",
      "  60   129     0.0024    0.0024   0.0000  1.5715  0.0580    *  3\n",
      "  70   129     0.0019    0.0019   0.0000  0.3598  0.3595       3\n",
      "  80   129     0.0054    0.0054  -0.0000  -0.3708  0.6446       3\n",
      "  90   130     0.0047    0.0048  -0.0001  -0.6854  0.7534       3\n",
      "\n",
      "H = 12\n",
      "Split  N    MSE_LSTM  MSE_HMM  dbar     DM      p     sig  q\n",
      "  60   121     0.0030    0.0029   0.0000  0.7491  0.2269       11\n",
      "  70   121     0.0036    0.0036   0.0001  1.2766  0.1009       11\n",
      "  80   121     0.0107    0.0105   0.0001  1.7361  0.0413   **  11\n",
      "  90   122     0.0129    0.0127   0.0002  1.3723  0.0850    *  11\n",
      "\n",
      "================ Pooled per horizon (one-sided) ================\n",
      "H=1 | N=529 | MSE: LSTM=0.0011, HMM=0.0011 | dbar=-0.0000 | DM=-0.4503 (p=0.6738)  | q=0 | HLN=True\n",
      "H=4 | N=517 | MSE: LSTM=0.0036, HMM=0.0036 | dbar=-0.0000 | DM=-0.5772 (p=0.7181)  | q=3 | HLN=True\n",
      "H=12 | N=485 | MSE: LSTM=0.0076, HMM=0.0074 | dbar=0.0001 | DM=2.3267 (p=0.0100) *** | q=11 | HLN=True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Optional, Dict, List\n",
    "\n",
    "# ------------------------ Paths -------------------------\n",
    "HMM_ROOT       = Path(\"/Users/anwarouni/Downloads/Thesis/Output\")  \n",
    "NEW_LSTM_ROOT  = Path(\"/Users/anwarouni/Downloads/Thesis/Output\") / \"LSTM predictionsTEST\"  \n",
    "OUTDIR         = Path(\"/Users/anwarouni/Downloads/Thesis/DM tests (HMM v LSTM NEW)\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------------- Config ------------------------------------------\n",
    "SPLITS    = [60, 70, 80, 90]\n",
    "HORIZONS  = [1, 4, 12]\n",
    "\n",
    "OVERLAPPING = True   # q = H-1\n",
    "USE_HLN     = True   # HLN correction ON\n",
    "\n",
    "# ----------------------------- Discovery ---------------------------------------\n",
    "def discover_csvs(root: Path, include_tokens: List[str], exclude_tokens: List[str]) -> List[Path]:\n",
    "    hits = []\n",
    "    for p in root.rglob(\"*.csv\"):\n",
    "        name = p.name.lower()\n",
    "        if all(tok in name for tok in include_tokens) and not any(tok in name for tok in exclude_tokens):\n",
    "            hits.append(p)\n",
    "    return sorted(hits)\n",
    "\n",
    "def _int_after(token: str, s: str) -> Optional[int]:\n",
    "    i = s.lower().rfind(token.lower())\n",
    "    if i < 0: return None\n",
    "    tail = s[i+len(token):]\n",
    "    m = re.search(r\"(\\d+)\", tail)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def parse_split_h(filename: str) -> Tuple[Optional[int], Optional[int]]:\n",
    "    split = _int_after(\"split\", filename)\n",
    "    h = _int_after(\"_h\", filename) or _int_after(\"h\", filename)\n",
    "    return split, h\n",
    "\n",
    "def index_files(paths: List[Path]) -> Dict[Tuple[int,int], Path]:\n",
    "    out: Dict[Tuple[int,int], Path] = {}\n",
    "    for p in paths:\n",
    "        s, h = parse_split_h(p.name)\n",
    "        if s in SPLITS and h in HORIZONS:\n",
    "            out[(s, h)] = p\n",
    "    return out\n",
    "\n",
    "# HMM-LSTM files (e.g., HMM_LSTM_split_60_H1.csv)\n",
    "HMM_FILES = discover_csvs(HMM_ROOT, include_tokens=[\"hmm\",\"lstm\",\"split\"], exclude_tokens=[\"dm\",\"test\"])\n",
    "HMM_MAP   = index_files(HMM_FILES)\n",
    "\n",
    "# Plain LSTM files in the NEW folder (e.g., LSTM_split_60_H1.csv)\n",
    "# NOTE: \n",
    "LSTM_FILES = discover_csvs(NEW_LSTM_ROOT, include_tokens=[\"lstm\",\"split\"], exclude_tokens=[\"hmm\"])\n",
    "LSTM_MAP   = index_files(LSTM_FILES)\n",
    "\n",
    "print(\"Matched HMM-LSTM:\", {k: v.name for k, v in HMM_MAP.items()})\n",
    "print(\"Matched LSTM (NEW):\", {k: v.name for k, v in LSTM_MAP.items()})\n",
    "\n",
    "# --------------------------- Column helpers -------------------------------------\n",
    "ACTUAL_CANDS       = [\"y_true\", \"actual\", \"y\", \"target\", \"swap spread\", \"truth\", \"true\"]\n",
    "FORECAST_ANY       = [\"y_hat\", \"forecast\", \"yhat\", \"pred\", \"prediction\"]\n",
    "FORECAST_HMM_PREF  = [\"forecast hmm lstm\", \"hmm_lstm_forecast\", \"y_hat_hmm\", \"hmm yhat\", \"hmm\"]\n",
    "\n",
    "def pick_actual_col(df: pd.DataFrame) -> str:\n",
    "    cols = [str(c).strip() for c in df.columns if not str(c).lower().startswith(\"unnamed\")]\n",
    "    for cand in ACTUAL_CANDS:\n",
    "        for c in cols:\n",
    "            if c.lower() == cand:\n",
    "                return c\n",
    "    for c in cols:  # fallback: first numeric\n",
    "        if pd.api.types.is_numeric_dtype(df[c]): return c\n",
    "    raise ValueError(\"Could not identify Actual column.\")\n",
    "\n",
    "def pick_forecast_col(df: pd.DataFrame, model: str) -> str:\n",
    "    cols  = [str(c).strip() for c in df.columns if not str(c).lower().startswith(\"unnamed\")]\n",
    "    lower = [c.lower() for c in cols]\n",
    "    if model.lower() == \"hmm_lstm\":\n",
    "        for pref in FORECAST_HMM_PREF:\n",
    "            for i, c in enumerate(lower):\n",
    "                if pref in c: return cols[i]\n",
    "        for i, c in enumerate(lower):\n",
    "            if any(k in c for k in FORECAST_ANY): return cols[i]\n",
    "    else:  # plain LSTM\n",
    "        for i, c in enumerate(lower):\n",
    "            if c == \"y_hat\": return cols[i]\n",
    "        for i, c in enumerate(lower):\n",
    "            if any(k in c for k in FORECAST_ANY) and (\"hmm\" not in c): return cols[i]\n",
    "    numeric = [c for c in cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if numeric: return numeric[-1]\n",
    "    raise ValueError(f\"Could not identify Forecast column for model={model}.\")\n",
    "\n",
    "def load_series(path: Path, model: str) -> Tuple[pd.Series, pd.Series]:\n",
    "    df = pd.read_csv(path)\n",
    "    # Optional Date index\n",
    "    date_col = None\n",
    "    for c in df.columns:\n",
    "        if str(c).lower() in [\"date\", \"time\", \"timestamp\"]:\n",
    "            date_col = c; break\n",
    "    if date_col is not None:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "        df = df.set_index(date_col)\n",
    "\n",
    "    a_col = pick_actual_col(df)\n",
    "    f_col = pick_forecast_col(df, model)\n",
    "    y    = pd.to_numeric(df[a_col], errors=\"coerce\")\n",
    "    yhat = pd.to_numeric(df[f_col], errors=\"coerce\")\n",
    "    s = pd.concat([y.rename(\"y\"), yhat.rename(\"yhat\")], axis=1).dropna()\n",
    "    return s[\"y\"], s[\"yhat\"]\n",
    "\n",
    "# --------------------------- DM machinery ---------------------------------------\n",
    "def nw_variance(d: np.ndarray, q: int) -> float:\n",
    "    T = len(d)\n",
    "    if T <= 1: return np.nan\n",
    "    dd = d - d.mean()\n",
    "    gamma0 = np.dot(dd, dd) / T\n",
    "    var = gamma0\n",
    "    for k in range(1, min(q, T-1) + 1):\n",
    "        w = 1.0 - k / (q + 1.0)            # Bartlett kernel\n",
    "        gamma_k = np.dot(dd[k:], dd[:-k]) / T\n",
    "        var += 2.0 * w * gamma_k\n",
    "    return var / T\n",
    "\n",
    "def dm_test_mse(e_lstm: np.ndarray, e_hmm: np.ndarray, h: int,\n",
    "                overlapping: bool = OVERLAPPING, use_hln: bool = USE_HLN):\n",
    "    \"\"\"\n",
    "    One-sided ALT='greater': tests HMM-LSTM has lower MSE than LSTM.\n",
    "    d_t = e_LSTM^2 - e_HMM^2 ; DM = dbar / se_NW.\n",
    "    \"\"\"\n",
    "    assert len(e_lstm) == len(e_hmm)\n",
    "    T = len(e_lstm)\n",
    "    d = (e_lstm**2) - (e_hmm**2)\n",
    "    q = max(h - 1, 0) if overlapping else 0\n",
    "\n",
    "    var = nw_variance(d, q)\n",
    "    if not np.isfinite(var) or var <= 0:\n",
    "        return np.nan, np.nan, T, float(np.mean(d)), np.nan, q\n",
    "\n",
    "    dbar = float(np.mean(d))\n",
    "    se   = math.sqrt(var)\n",
    "    dm   = dbar / se\n",
    "\n",
    "    if use_hln:\n",
    "        # Harvey–Leybourne–Newbold correction\n",
    "        hln = math.sqrt((T + 1 - 2*h + (h*(h-1))/T) / T) if T > 0 else np.nan\n",
    "        dm *= hln\n",
    "\n",
    "    from math import erf, sqrt\n",
    "    def norm_cdf(x): return 0.5*(1 + erf(x / sqrt(2)))\n",
    "    p = 1 - norm_cdf(dm)  # one-sided 'greater'\n",
    "    return dm, p, T, dbar, se, q\n",
    "\n",
    "def stars(p):\n",
    "    return \"***\" if (p is not None and p < 0.01) else (\"**\" if (p is not None and p < 0.05) else (\"*\" if (p is not None and p < 0.10) else \"\"))\n",
    "\n",
    "def nan_row(extra: dict) -> dict:\n",
    "    base = {\n",
    "        \"N\": 0,\n",
    "        \"MSE_LSTM\": np.nan, \"MSE_HMM_LSTM\": np.nan,\n",
    "        \"RMSE_LSTM\": np.nan, \"RMSE_HMM_LSTM\": np.nan,\n",
    "        \"dbar\": np.nan, \"SE_NW\": np.nan, \"q_lag\": np.nan,\n",
    "        \"DM\": np.nan, \"p_value\": np.nan, \"sig\": \"\",\n",
    "        \"ALT\": \"greater\", \"HLN\": USE_HLN, \"overlapping\": OVERLAPPING\n",
    "    }\n",
    "    base.update(extra); return base\n",
    "\n",
    "# ----------------------- Per split × horizon ------------------------------------\n",
    "rows = []\n",
    "for s in SPLITS:\n",
    "    for h in HORIZONS:\n",
    "        p_l = LSTM_MAP.get((s, h)); p_h = HMM_MAP.get((s, h))\n",
    "        if p_l is None or p_h is None:\n",
    "            rows.append(nan_row({\"Split\": s, \"H\": h, \"note\": \"missing file(s)\"}))\n",
    "            continue\n",
    "        try:\n",
    "            y_l, f_l = load_series(p_l, model=\"LSTM\")\n",
    "            y_h, f_h = load_series(p_h, model=\"HMM_LSTM\")\n",
    "            df = pd.concat([y_l.rename(\"y\"), f_l.rename(\"f_lstm\"),\n",
    "                            y_h.rename(\"y2\"), f_h.rename(\"f_hmm\")], axis=1).dropna()\n",
    "            if df.empty:\n",
    "                rows.append(nan_row({\"Split\": s, \"H\": h, \"note\": \"no overlap after merge\"}))\n",
    "                continue\n",
    "\n",
    "            y  = df[\"y\"]  # equals y2 after merge\n",
    "            eL = (y - df[\"f_lstm\"]).to_numpy()\n",
    "            eH = (y - df[\"f_hmm\"]).to_numpy()\n",
    "\n",
    "            DM, p, T, dbar, se, q = dm_test_mse(eL, eH, h=h)\n",
    "\n",
    "            mse_l = float(np.mean(eL**2)); mse_h = float(np.mean(eH**2))\n",
    "            rmse_l = float(np.sqrt(mse_l)); rmse_h = float(np.sqrt(mse_h))\n",
    "\n",
    "            rows.append({\n",
    "                \"Split\": s, \"H\": h, \"N\": int(T),\n",
    "                \"MSE_LSTM\": mse_l, \"MSE_HMM_LSTM\": mse_h,\n",
    "                \"RMSE_LSTM\": rmse_l, \"RMSE_HMM_LSTM\": rmse_h,\n",
    "                \"dbar\": dbar, \"SE_NW\": se, \"q_lag\": q,\n",
    "                \"DM\": DM, \"p_value\": p, \"sig\": stars(p),\n",
    "                \"ALT\": \"greater\", \"HLN\": USE_HLN, \"overlapping\": OVERLAPPING\n",
    "            })\n",
    "        except Exception as ex:\n",
    "            rows.append(nan_row({\"Split\": s, \"H\": h, \"note\": \"exception\", \"error\": str(ex)}))\n",
    "\n",
    "by_split = pd.DataFrame(rows).sort_values([\"H\",\"Split\"]).reset_index(drop=True)\n",
    "by_split_path = OUTDIR / \"DM_HMM_LSTM_vs_LSTM_NEW_by_split_MSE_one_sided_HLN.csv\"\n",
    "by_split.to_csv(by_split_path, index=False)\n",
    "print(f\"Saved per-split results → {by_split_path}\")\n",
    "\n",
    "# --------------------------- Pooled per horizon ---------------------------------\n",
    "pooled_rows = []\n",
    "for h in HORIZONS:\n",
    "    eL_all, eH_all = [], []\n",
    "    for s in SPLITS:\n",
    "        p_l = LSTM_MAP.get((s, h)); p_h = HMM_MAP.get((s, h))\n",
    "        if p_l is None or p_h is None: continue\n",
    "        y_l, f_l = load_series(p_l, model=\"LSTM\")\n",
    "        y_h, f_h = load_series(p_h, model=\"HMM_LSTM\")\n",
    "        df = pd.concat([y_l.rename(\"y\"), f_l.rename(\"f_lstm\"),\n",
    "                        y_h.rename(\"y2\"), f_h.rename(\"f_hmm\")], axis=1).dropna()\n",
    "        if not df.empty:\n",
    "            y  = df[\"y\"]\n",
    "            eL = (y - df[\"f_lstm\"]).to_numpy()\n",
    "            eH = (y - df[\"f_hmm\"]).to_numpy()\n",
    "            eL_all.append(eL); eH_all.append(eH)\n",
    "\n",
    "    if not eL_all:\n",
    "        pooled_rows.append(nan_row({\"H\": h, \"N_total\": 0, \"note\": \"no data\"}))\n",
    "        continue\n",
    "\n",
    "    eL = np.concatenate(eL_all, axis=0)\n",
    "    eH = np.concatenate(eH_all, axis=0)\n",
    "\n",
    "    DM, p, T, dbar, se, q = dm_test_mse(eL, eH, h=h)\n",
    "\n",
    "    mse_l = float(np.mean(eL**2)); mse_h = float(np.mean(eH**2))\n",
    "    rmse_l = float(np.sqrt(mse_l)); rmse_h = float(np.sqrt(mse_h))\n",
    "\n",
    "    pooled_rows.append({\n",
    "        \"H\": h, \"N_total\": int(T),\n",
    "        \"MSE_LSTM\": mse_l, \"MSE_HMM_LSTM\": mse_h,\n",
    "        \"RMSE_LSTM\": rmse_l, \"RMSE_HMM_LSTM\": rmse_h,\n",
    "        \"dbar\": dbar, \"SE_NW\": se, \"q_lag\": q,\n",
    "        \"DM\": DM, \"p_value\": p, \"sig\": stars(p),\n",
    "        \"ALT\": \"greater\", \"HLN\": USE_HLN, \"overlapping\": OVERLAPPING\n",
    "    })\n",
    "\n",
    "pooled = pd.DataFrame(pooled_rows).sort_values(\"H\").reset_index(drop=True)\n",
    "pooled_path = OUTDIR / \"DM_HMM_LSTM_vs_LSTM_NEW_by_horizon_MSE_one_sided_HLN.csv\"\n",
    "pooled.to_csv(pooled_path, index=False)\n",
    "print(f\"Saved pooled results → {pooled_path}\")\n",
    "\n",
    "# --------------------------- Console preview ------------------------------------\n",
    "def fmt(x):\n",
    "    if x is None or (isinstance(x, float) and not np.isfinite(x)): return \"—\"\n",
    "    return f\"{x:.4f}\" if isinstance(x, float) else str(x)\n",
    "\n",
    "print(\"\\n============= ONE-SIDED DM (HMM-LSTM better) — MSE (HLN ON) =============\")\n",
    "for h in HORIZONS:\n",
    "    sub = by_split[by_split[\"H\"] == h]\n",
    "    if sub.empty: continue\n",
    "    print(f\"\\nH = {h}\")\n",
    "    print(\"Split  N    MSE_LSTM  MSE_HMM  dbar     DM      p     sig  q\")\n",
    "    for _, r in sub.iterrows():\n",
    "        print(f\"{int(r['Split']):>4}  {int(r['N']):>4}  {fmt(r['MSE_LSTM']):>9}  {fmt(r['MSE_HMM_LSTM']):>8}  \"\n",
    "              f\"{fmt(r['dbar']):>7}  {fmt(r['DM']):>6}  {fmt(r['p_value']):>6}  {r['sig']:>3}  {int(r['q_lag']):>1}\")\n",
    "\n",
    "print(\"\\n================ Pooled per horizon (one-sided) ================\")\n",
    "for _, r in pooled.iterrows():\n",
    "    print(f\"H={int(r['H'])} | N={int(r.get('N_total',0))} | \"\n",
    "          f\"MSE: LSTM={fmt(r.get('MSE_LSTM'))}, HMM={fmt(r.get('MSE_HMM_LSTM'))} | \"\n",
    "          f\"dbar={fmt(r.get('dbar'))} | DM={fmt(r.get('DM'))} (p={fmt(r.get('p_value'))}) {r.get('sig','')} \"\n",
    "          f\"| q={int(r['q_lag'])} | HLN={r['HLN']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched HMM-LSTM: {(60, 1): 'HMM_LSTM_split_60_H1.csv', (60, 12): 'HMM_LSTM_split_60_H12.csv', (60, 4): 'HMM_LSTM_split_60_H4.csv', (70, 1): 'HMM_LSTM_split_70_H1.csv', (70, 12): 'HMM_LSTM_split_70_H12.csv', (70, 4): 'HMM_LSTM_split_70_H4.csv', (80, 1): 'HMM_LSTM_split_80_H1.csv', (80, 12): 'HMM_LSTM_split_80_H12.csv', (80, 4): 'HMM_LSTM_split_80_H4.csv', (90, 1): 'HMM_LSTM_split_90_H1.csv', (90, 12): 'HMM_LSTM_split_90_H12.csv', (90, 4): 'HMM_LSTM_split_90_H4.csv'}\n",
      "Matched ARMA(1,1): {(60, 1): 'arma11_split_60_h1.csv', (60, 12): 'arma11_split_60_h12.csv', (60, 4): 'arma11_split_60_h4.csv', (70, 1): 'arma11_split_70_h1.csv', (70, 12): 'arma11_split_70_h12.csv', (70, 4): 'arma11_split_70_h4.csv', (80, 1): 'arma11_split_80_h1.csv', (80, 12): 'arma11_split_80_h12.csv', (80, 4): 'arma11_split_80_h4.csv', (90, 1): 'arma11_split_90_h1.csv', (90, 12): 'arma11_split_90_h12.csv', (90, 4): 'arma11_split_90_h4.csv'}\n",
      "Saved per-split results → /Users/anwarouni/Downloads/Thesis/Output/DM tests/DM_HMM_LSTM_vs_ARMA11_by_split_MSE_one_sided_HLN.csv\n",
      "Saved pooled results → /Users/anwarouni/Downloads/Thesis/Output/DM tests/DM_HMM_LSTM_vs_ARMA11_by_horizon_MSE_one_sided_HLN.csv\n",
      "\n",
      "============= ONE-SIDED DM (HMM_LSTM < ARMA11) — MSE (HLN ON) =============\n",
      "\n",
      "H = 1\n",
      "Split  N    MSE_  ARMA11  MSE_    HMM_LSTM  dbar     DM      p     sig  q\n",
      "  60   132        0.0008        0.0008   0.0000  0.0585  0.4767       0\n",
      "  70   132        0.0007        0.0007   0.0000  0.2303  0.4089       0\n",
      "  80   132        0.0017        0.0017  -0.0000  -0.1930  0.5765       0\n",
      "  90   122        0.0015        0.0014   0.0001  2.0977  0.0180   **  0\n",
      "\n",
      "H = 4\n",
      "Split  N    MSE_  ARMA11  MSE_    HMM_LSTM  dbar     DM      p     sig  q\n",
      "  60   129        0.0023        0.0024  -0.0001  -0.9498  0.8289       3\n",
      "  70   129        0.0018        0.0019  -0.0001  -0.8170  0.7930       3\n",
      "  80   129        0.0055        0.0054   0.0001  0.4393  0.3302       3\n",
      "  90   122        0.0048        0.0050  -0.0001  -1.0122  0.8443       3\n",
      "\n",
      "H = 12\n",
      "Split  N    MSE_  ARMA11  MSE_    HMM_LSTM  dbar     DM      p     sig  q\n",
      "  60   121        0.0034        0.0029   0.0004  0.9703  0.1659       11\n",
      "  70   121        0.0036        0.0036   0.0000  0.0246  0.4902       11\n",
      "  80   121        0.0130        0.0105   0.0024  2.2811  0.0113   **  11\n",
      "  90   122        0.0122        0.0127  -0.0005  -1.5516  0.9396       11\n",
      "\n",
      "================ Pooled per horizon (one-sided) ================\n",
      "H=1 | N=518 | MSE: ARMA(1,1)=0.0012, HMM-LSTM=0.0012 | dbar=0.0000 | DM=0.8288 (p=0.2036)  | q=0 | HLN=True\n",
      "H=4 | N=509 | MSE: ARMA(1,1)=0.0036, HMM-LSTM=0.0036 | dbar=-0.0001 | DM=-0.7952 (p=0.7867)  | q=3 | HLN=True\n",
      "H=12 | N=485 | MSE: ARMA(1,1)=0.0080, HMM-LSTM=0.0074 | dbar=0.0006 | DM=1.7096 (p=0.0437) ** | q=11 | HLN=True\n"
     ]
    }
   ],
   "source": [
    "import re, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Optional, Dict, List\n",
    "\n",
    "# ----------------------------- Config / Paths -----------------------------------\n",
    "ROOT      = Path(\"/Users/anwarouni/Downloads/Thesis/Output\")\n",
    "OUTDIR    = ROOT / \"DM tests\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SPLITS    = [60, 70, 80, 90]\n",
    "HORIZONS  = [1, 4, 12]\n",
    "\n",
    "# Candidate vs Baseline\n",
    "CAND_NAME      = \"HMM_LSTM\"\n",
    "BASE_NAME      = \"ARMA11\"   # plain ARMA(1,1), not ARMAX, not \"arma11x\"\n",
    "\n",
    "OVERLAPPING   = True        # q = H-1 if True; else q=0\n",
    "USE_HLN       = True        # HLN correction ON\n",
    "ALT           = \"greater\"   # one-sided: dbar > 0 ⇒ HMM-LSTM better (lower MSE)\n",
    "\n",
    "\n",
    "def discover_csvs_regex(root: Path,\n",
    "                        include_patterns: List[str],\n",
    "                        exclude_patterns: List[str]) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Regex-based discovery. A file is selected iff it matches ALL include_patterns\n",
    "    and NONE of the exclude_patterns. Matching is case-insensitive.\n",
    "    \"\"\"\n",
    "    hits = []\n",
    "    for p in root.rglob(\"*.csv\"):\n",
    "        name = p.name.lower()\n",
    "        ok_inc = all(re.search(pat, name, flags=re.IGNORECASE) for pat in include_patterns)\n",
    "        ok_exc = any(re.search(pat, name, flags=re.IGNORECASE) for pat in exclude_patterns)\n",
    "        if ok_inc and not ok_exc:\n",
    "            hits.append(p)\n",
    "    return sorted(hits)\n",
    "\n",
    "def _int_after(token: str, s: str) -> Optional[int]:\n",
    "    i = s.lower().rfind(token.lower())\n",
    "    if i < 0: return None\n",
    "    tail = s[i+len(token):]\n",
    "    m = re.search(r\"(\\d+)\", tail)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def parse_split_h(filename: str) -> Tuple[Optional[int], Optional[int]]:\n",
    "    split = _int_after(\"split\", filename)\n",
    "    h = _int_after(\"_h\", filename) or _int_after(\"h\", filename)\n",
    "    return split, h\n",
    "\n",
    "def index_files(paths: List[Path]) -> Dict[Tuple[int,int], Path]:\n",
    "    out: Dict[Tuple[int,int], Path] = {}\n",
    "    for p in paths:\n",
    "        s, h = parse_split_h(p.name)\n",
    "        if s in SPLITS and h in HORIZONS:\n",
    "            out[(s, h)] = p\n",
    "    return out\n",
    "\n",
    "# HMM-LSTM files (e.g., HMM_LSTM_split_60_H1.csv)\n",
    "HMM_FILES = discover_csvs_regex(\n",
    "    ROOT,\n",
    "    include_patterns=[r\"hmm\", r\"lstm\", r\"split\"],\n",
    "    exclude_patterns=[r\"dm\", r\"test\"]\n",
    ")\n",
    "HMM_MAP   = index_files(HMM_FILES)\n",
    "\n",
    "\n",
    "ARMA11_FILES = discover_csvs_regex(\n",
    "    ROOT,\n",
    "    include_patterns=[r\"(^|[_-])arma11([_-])\", r\"split\"],\n",
    "    exclude_patterns=[r\"armax\", r\"arma11x\", r\"hmm\", r\"lstm\", r\"arx\", r\"garch\"]\n",
    ")\n",
    "ARIMA11_FILES = discover_csvs_regex(\n",
    "    ROOT,\n",
    "    include_patterns=[r\"(^|[_-])arima11([_-])\", r\"split\"],\n",
    "    exclude_patterns=[r\"armax\", r\"arma11x\", r\"hmm\", r\"lstm\", r\"arx\", r\"garch\"]\n",
    ")\n",
    "BASE_FILES = sorted(set(ARMA11_FILES + ARIMA11_FILES), key=lambda p: p.as_posix())\n",
    "BASE_MAP   = index_files(BASE_FILES)\n",
    "\n",
    "print(\"Matched HMM-LSTM:\", {k: v.name for k, v in HMM_MAP.items()})\n",
    "print(\"Matched ARMA(1,1):\", {k: v.name for k, v in BASE_MAP.items()})\n",
    "\n",
    "# ----------------------------- Column helpers -----------------------------------\n",
    "ACTUAL_CANDS = [\"y_true\", \"actual\", \"y\", \"target\", \"swap spread\", \"truth\", \"true\"]\n",
    "FORECAST_ANY = [\"y_hat\", \"forecast\", \"yhat\", \"pred\", \"prediction\"]\n",
    "\n",
    "FORECAST_PREFS = {\n",
    "    \"HMM_LSTM\": [\"forecast hmm lstm\", \"hmm_lstm_forecast\", \"y_hat_hmm\", \"yhat_hmm\", \"hmm yhat\", \"hmm\"],\n",
    "    \"ARMA11\":   [\"arma11\", \"arima11\", \"arma(1,1)\", \"arima(1,1)\", \"y_hat_arma11\", \"yhat_arma11\",\n",
    "                 \"forecast_arma11\", \"y_hat_arma\"],\n",
    "}\n",
    "\n",
    "def pick_actual_col(df: pd.DataFrame) -> str:\n",
    "    cols = [str(c).strip() for c in df.columns if not str(c).lower().startswith(\"unnamed\")]\n",
    "    for cand in ACTUAL_CANDS:\n",
    "        for c in cols:\n",
    "            if c.lower() == cand:\n",
    "                return c\n",
    "    for c in cols:\n",
    "        if pd.api.types.is_numeric_dtype(df[c]): return c\n",
    "    raise ValueError(\"Could not identify the Actual column (e.g., y_true).\")\n",
    "\n",
    "def pick_forecast_col(df: pd.DataFrame, model_key: str) -> str:\n",
    "    cols  = [str(c).strip() for c in df.columns if not str(c).lower().startswith(\"unnamed\")]\n",
    "    lower = [c.lower() for c in cols]\n",
    "    # Prefer model-specific tokens\n",
    "    for pref in FORECAST_PREFS.get(model_key, []):\n",
    "        for i, c in enumerate(lower):\n",
    "            if pref in c:\n",
    "                return cols[i]\n",
    "    # Fallback: generic forecast column (safe if each CSV is model-specific)\n",
    "    for i, c in enumerate(lower):\n",
    "        if any(k in c for k in FORECAST_ANY):\n",
    "            if model_key != \"HMM_LSTM\" and \"hmm\" in c:\n",
    "                continue\n",
    "            return cols[i]\n",
    "    # Last resort: last numeric column\n",
    "    numeric = [c for c in cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if numeric: return numeric[-1]\n",
    "    raise ValueError(f\"Could not identify Forecast column for model={model_key}.\")\n",
    "\n",
    "def load_series(path: Path, model_key: str) -> Tuple[pd.Series, pd.Series]:\n",
    "    df = pd.read_csv(path)\n",
    "    # Optional Date index\n",
    "    date_col = None\n",
    "    for c in df.columns:\n",
    "        if str(c).lower() in [\"date\", \"time\", \"timestamp\"]:\n",
    "            date_col = c; break\n",
    "    if date_col is not None:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "        df = df.set_index(date_col)\n",
    "\n",
    "    a_col = pick_actual_col(df)\n",
    "    f_col = pick_forecast_col(df, model_key)\n",
    "\n",
    "    # DEBUG (uncomment if needed):\n",
    "    # print(f\"[{model_key}] file={path.name} | actual={a_col} | forecast={f_col}\")\n",
    "\n",
    "    y    = pd.to_numeric(df[a_col], errors=\"coerce\")\n",
    "    yhat = pd.to_numeric(df[f_col], errors=\"coerce\")\n",
    "    s = pd.concat([y.rename(\"y\"), yhat.rename(\"yhat\")], axis=1).dropna()\n",
    "    return s[\"y\"], s[\"yhat\"]\n",
    "\n",
    "# ----------------------------- Newey–West variance -------------------------------\n",
    "def nw_variance(d: np.ndarray, q: int) -> float:\n",
    "    T = len(d)\n",
    "    if T <= 1: return np.nan\n",
    "    dd = d - d.mean()\n",
    "    gamma0 = np.dot(dd, dd) / T\n",
    "    var = gamma0\n",
    "    for k in range(1, min(q, T-1) + 1):\n",
    "        w = 1.0 - k / (q + 1.0)            # Bartlett kernel\n",
    "        gamma_k = np.dot(dd[k:], dd[:-k]) / T\n",
    "        var += 2.0 * w * gamma_k\n",
    "    return var / T\n",
    "\n",
    "# ----------------------------- DM over MSE (HLN ON) ------------------------------\n",
    "def dm_test_mse(e_base: np.ndarray, e_cand: np.ndarray, h: int,\n",
    "                overlapping: bool = OVERLAPPING, use_hln: bool = USE_HLN):\n",
    "    \"\"\"\n",
    "    Returns: DM_stat, p_value (one-sided ALT='greater'), T, dbar, se_NW, q_lag\n",
    "    d_t = e_base^2 - e_cand^2 ; ALT 'greater' tests Candidate (HMM-LSTM) better (lower MSE).\n",
    "    \"\"\"\n",
    "    assert len(e_base) == len(e_cand)\n",
    "    T = len(e_base)\n",
    "    d = (e_base**2) - (e_cand**2)\n",
    "    q = max(h - 1, 0) if overlapping else 0\n",
    "\n",
    "    var = nw_variance(d, q)\n",
    "    if not np.isfinite(var) or var <= 0:\n",
    "        return np.nan, np.nan, T, float(np.mean(d)), np.nan, q\n",
    "\n",
    "    dbar = float(np.mean(d))\n",
    "    se   = math.sqrt(var)\n",
    "    dm   = dbar / se\n",
    "\n",
    "    if use_hln:\n",
    "        # Harvey–Leybourne–Newbold small-sample correction\n",
    "        hln = math.sqrt((T + 1 - 2*h + (h*(h-1))/T) / T) if T > 0 else np.nan\n",
    "        dm *= hln\n",
    "\n",
    "    from math import erf, sqrt\n",
    "    def norm_cdf(x): return 0.5*(1 + erf(x / sqrt(2)))\n",
    "    p = 1 - norm_cdf(dm)  # one-sided: greater\n",
    "    return dm, p, T, dbar, se, q\n",
    "\n",
    "def stars(p):\n",
    "    return \"***\" if (p is not None and p < 0.01) else (\"**\" if (p is not None and p < 0.05) else (\"*\" if (p is not None and p < 0.10) else \"\"))\n",
    "\n",
    "def nan_row(extra: dict) -> dict:\n",
    "    base = {\n",
    "        \"N\": 0,\n",
    "        f\"MSE_{BASE_NAME}\": np.nan, f\"MSE_{CAND_NAME}\": np.nan,\n",
    "        f\"RMSE_{BASE_NAME}\": np.nan, f\"RMSE_{CAND_NAME}\": np.nan,\n",
    "        \"dbar\": np.nan, \"SE_NW\": np.nan, \"q_lag\": np.nan,\n",
    "        \"DM\": np.nan, \"p_value\": np.nan, \"sig\": \"\",\n",
    "        \"ALT\": ALT, \"HLN\": USE_HLN, \"overlapping\": OVERLAPPING\n",
    "    }\n",
    "    base.update(extra); return base\n",
    "\n",
    "# ----------------------------- Per split × horizon ------------------------------\n",
    "rows = []\n",
    "for s in SPLITS:\n",
    "    for h in HORIZONS:\n",
    "        p_b = BASE_MAP.get((s, h)); p_c = HMM_MAP.get((s, h))\n",
    "        if p_b is None or p_c is None:\n",
    "            rows.append(nan_row({\"Split\": s, \"H\": h, \"note\": \"missing file(s)\"}))\n",
    "            continue\n",
    "        try:\n",
    "            y_b, f_b = load_series(p_b, model_key=BASE_NAME)\n",
    "            y_c, f_c = load_series(p_c, model_key=CAND_NAME)\n",
    "            df = pd.concat([y_b.rename(\"y\"), f_b.rename(\"f_base\"),\n",
    "                            y_c.rename(\"y2\"), f_c.rename(\"f_cand\")], axis=1).dropna()\n",
    "            if df.empty:\n",
    "                rows.append(nan_row({\"Split\": s, \"H\": h, \"note\": \"no overlap after merge\"}))\n",
    "                continue\n",
    "\n",
    "            y   = df[\"y\"]  # equals y2 after merge\n",
    "            eB  = (y - df[\"f_base\"]).to_numpy()\n",
    "            eC  = (y - df[\"f_cand\"]).to_numpy()\n",
    "\n",
    "            DM, p, T, dbar, se, q = dm_test_mse(eB, eC, h=h)\n",
    "\n",
    "            mse_b = float(np.mean(eB**2)); mse_c = float(np.mean(eC**2))\n",
    "            rmse_b = float(np.sqrt(mse_b)); rmse_c = float(np.sqrt(mse_c))\n",
    "\n",
    "            rows.append({\n",
    "                \"Split\": s, \"H\": h, \"N\": int(T),\n",
    "                f\"MSE_{BASE_NAME}\": mse_b, f\"MSE_{CAND_NAME}\": mse_c,\n",
    "                f\"RMSE_{BASE_NAME}\": rmse_b, f\"RMSE_{CAND_NAME}\": rmse_c,\n",
    "                \"dbar\": dbar, \"SE_NW\": se, \"q_lag\": q,\n",
    "                \"DM\": DM, \"p_value\": p, \"sig\": stars(p),\n",
    "                \"ALT\": ALT, \"HLN\": USE_HLN, \"overlapping\": OVERLAPPING\n",
    "            })\n",
    "        except Exception as ex:\n",
    "            rows.append(nan_row({\"Split\": s, \"H\": h, \"note\": \"exception\", \"error\": str(ex)}))\n",
    "\n",
    "by_split = pd.DataFrame(rows).sort_values([\"H\",\"Split\"]).reset_index(drop=True)\n",
    "by_split_path = OUTDIR / f\"DM_{CAND_NAME}_vs_{BASE_NAME}_by_split_MSE_one_sided_HLN.csv\"\n",
    "by_split.to_csv(by_split_path, index=False)\n",
    "print(f\"Saved per-split results → {by_split_path}\")\n",
    "\n",
    "# ----------------------------- Pooled per horizon --------------------------------\n",
    "pooled_rows = []\n",
    "for h in HORIZONS:\n",
    "    eB_all, eC_all = [], []\n",
    "    for s in SPLITS:\n",
    "        p_b = BASE_MAP.get((s, h)); p_c = HMM_MAP.get((s, h))\n",
    "        if p_b is None or p_c is None: continue\n",
    "        y_b, f_b = load_series(p_b, model_key=BASE_NAME)\n",
    "        y_c, f_c = load_series(p_c, model_key=CAND_NAME)\n",
    "        df = pd.concat([y_b.rename(\"y\"), f_b.rename(\"f_base\"),\n",
    "                        y_c.rename(\"y2\"), f_c.rename(\"f_cand\")], axis=1).dropna()\n",
    "        if not df.empty:\n",
    "            y   = df[\"y\"]\n",
    "            eB  = (y - df[\"f_base\"]).to_numpy()\n",
    "            eC  = (y - df[\"f_cand\"]).to_numpy()\n",
    "            eB_all.append(eB); eC_all.append(eC)\n",
    "\n",
    "    if not eB_all:\n",
    "        pooled_rows.append(nan_row({\"H\": h, \"N_total\": 0, \"note\": \"no data\"}))\n",
    "        continue\n",
    "\n",
    "    eB = np.concatenate(eB_all, axis=0)\n",
    "    eC = np.concatenate(eC_all, axis=0)\n",
    "\n",
    "    DM, p, T, dbar, se, q = dm_test_mse(eB, eC, h=h)\n",
    "\n",
    "    mse_b = float(np.mean(eB**2)); mse_c = float(np.mean(eC**2))\n",
    "    rmse_b = float(np.sqrt(mse_b)); rmse_c = float(np.sqrt(mse_c))\n",
    "\n",
    "    pooled_rows.append({\n",
    "        \"H\": h, \"N_total\": int(T),\n",
    "        f\"MSE_{BASE_NAME}\": mse_b, f\"MSE_{CAND_NAME}\": mse_c,\n",
    "        f\"RMSE_{BASE_NAME}\": rmse_b, f\"RMSE_{CAND_NAME}\": rmse_c,\n",
    "        \"dbar\": dbar, \"SE_NW\": se, \"q_lag\": q,\n",
    "        \"DM\": DM, \"p_value\": p, \"sig\": stars(p),\n",
    "        \"ALT\": ALT, \"HLN\": USE_HLN, \"overlapping\": OVERLAPPING\n",
    "    })\n",
    "\n",
    "pooled = pd.DataFrame(pooled_rows).sort_values(\"H\").reset_index(drop=True)\n",
    "pooled_path = OUTDIR / f\"DM_{CAND_NAME}_vs_{BASE_NAME}_by_horizon_MSE_one_sided_HLN.csv\"\n",
    "pooled.to_csv(pooled_path, index=False)\n",
    "print(f\"Saved pooled results → {pooled_path}\")\n",
    "\n",
    "# ----------------------------- Console preview -----------------------------------\n",
    "def fmt(x):\n",
    "    if x is None or (isinstance(x, float) and not np.isfinite(x)): return \"—\"\n",
    "    return f\"{x:.4f}\" if isinstance(x, float) else str(x)\n",
    "\n",
    "print(f\"\\n============= ONE-SIDED DM ({CAND_NAME} < {BASE_NAME}) — MSE (HLN ON) =============\")\n",
    "for h in HORIZONS:\n",
    "    sub = by_split[by_split[\"H\"] == h]\n",
    "    if sub.empty: continue\n",
    "    print(f\"\\nH = {h}\")\n",
    "    print(f\"Split  N    MSE_{BASE_NAME:>8}  MSE_{CAND_NAME:>12}  dbar     DM      p     sig  q\")\n",
    "    for _, r in sub.iterrows():\n",
    "        print(f\"{int(r['Split']):>4}  {int(r['N']):>4}  {fmt(r[f'MSE_{BASE_NAME}']):>12}  {fmt(r[f'MSE_{CAND_NAME}']):>12}  \"\n",
    "              f\"{fmt(r['dbar']):>7}  {fmt(r['DM']):>6}  {fmt(r['p_value']):>6}  {r['sig']:>3}  {int(r['q_lag']):>1}\")\n",
    "\n",
    "print(\"\\n================ Pooled per horizon (one-sided) ================\")\n",
    "for _, r in pooled.iterrows():\n",
    "    print(f\"H={int(r['H'])} | N={int(r.get('N_total',0))} | \"\n",
    "          f\"MSE: ARMA(1,1)={fmt(r.get(f'MSE_{BASE_NAME}'))}, HMM-LSTM={fmt(r.get(f'MSE_{CAND_NAME}'))} | \"\n",
    "          f\"dbar={fmt(r.get('dbar'))} | DM={fmt(r.get('DM'))} (p={fmt(r.get('p_value'))}) {r.get('sig','')} \"\n",
    "          f\"| q={int(r['q_lag'])} | HLN={r['HLN']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
